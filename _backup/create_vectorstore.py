#!/usr/bin/env python3
"""
Script para criar VectorStore com ChromaDB e Embeddings HuggingFace
Processa todos os documentos da pasta matem√°tica para criar sistema RAG
"""

import os
import sys
from pathlib import Path
import time
from typing import List, Dict, Any

# LangChain imports
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain.schema import Document

# Embeddings
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings

# Processadores de documentos
try:
    import docx
    from pypdf import PdfReader
    DOCUMENT_PROCESSING_AVAILABLE = True
except ImportError:
    print("‚ùå Instale as depend√™ncias: pip install python-docx pypdf")
    sys.exit(1)

class MathVectorStoreCreator:
    """Criador de VectorStore para documentos de matem√°tica"""
    
    def __init__(self, math_folder: str = "./matem√°tica", persist_dir: str = "./chroma_math_vectorstore"):
        self.math_folder = Path(math_folder)
        self.persist_dir = persist_dir
        self.embeddings = None
        self.vectorstore = None
        self.documents = []
        
        # Configura√ß√£o do text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        
        print(f"üéØ Configura√ß√£o:")
        print(f"   üìÅ Pasta origem: {self.math_folder}")
        print(f"   üíæ Diret√≥rio persist√™ncia: {self.persist_dir}")
    
    def setup_embeddings(self):
        """Configura embeddings HuggingFace"""
        print("\nüß† Configurando embeddings HuggingFace...")
        
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            print("‚úÖ Embeddings configurados: sentence-transformers/all-MiniLM-L6-v2")
            
            # Teste r√°pido
            test_embedding = self.embeddings.embed_query("teste")
            print(f"‚úÖ Teste de embedding: dimens√£o {len(test_embedding)}")
            
        except Exception as e:
            print(f"‚ùå Erro ao configurar embeddings: {e}")
            sys.exit(1)
    
    def find_math_documents(self) -> List[Path]:
        """Encontra todos os documentos de matem√°tica"""
        print(f"\nüìÇ Buscando documentos em {self.math_folder}...")
        
        if not self.math_folder.exists():
            print(f"‚ùå Pasta n√£o encontrada: {self.math_folder}")
            return []
        
        # Busca arquivos suportados
        supported_extensions = ['.docx', '.pdf', '.txt']
        documents = []
        
        for ext in supported_extensions:
            files = list(self.math_folder.glob(f"*{ext}"))
            documents.extend(files)
            print(f"   üìÑ {ext.upper()}: {len(files)} arquivos")
        
        print(f"üìä Total: {len(documents)} documentos encontrados")
        return documents
    
    def extract_content_from_docx(self, file_path: Path) -> str:
        """Extrai conte√∫do de arquivo DOCX"""
        try:
            doc = docx.Document(file_path)
            content_parts = []
            
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    content_parts.append(paragraph.text.strip())
            
            return "\n\n".join(content_parts)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao processar {file_path.name}: {e}")
            return ""
    
    def extract_content_from_pdf(self, file_path: Path) -> str:
        """Extrai conte√∫do de arquivo PDF"""
        try:
            reader = PdfReader(file_path)
            content_parts = []
            
            for page_num, page in enumerate(reader.pages):
                try:
                    text = page.extract_text()
                    if text.strip():
                        content_parts.append(text.strip())
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro na p√°gina {page_num + 1} de {file_path.name}: {e}")
                    continue
            
            return "\n\n".join(content_parts)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao processar {file_path.name}: {e}")
            return ""
    
    def process_single_document(self, file_path: Path) -> List[Document]:
        """Processa um √∫nico documento"""
        file_extension = file_path.suffix.lower()
        file_name = file_path.name
        
        print(f"   üìÑ Processando: {file_name}")
        
        # Extrai conte√∫do baseado no tipo
        if file_extension == '.docx':
            content = self.extract_content_from_docx(file_path)
        elif file_extension == '.pdf':
            content = self.extract_content_from_pdf(file_path)
        else:
            print(f"‚ö†Ô∏è  Tipo n√£o suportado: {file_extension}")
            return []
        
        if not content.strip():
            print(f"‚ö†Ô∏è  Conte√∫do vazio: {file_name}")
            return []
        
        # Identifica t√≥pico do nome do arquivo
        topic = file_name.replace('.docx', '').replace('.pdf', '').replace('_', ' ')
        
        # Cria documento LangChain
        doc = Document(
            page_content=content,
            metadata={
                "source": file_name,
                "file_path": str(file_path),
                "type": "matematica",
                "topic": topic,
                "extension": file_extension
            }
        )
        
        # Divide em chunks
        chunks = self.text_splitter.split_documents([doc])
        
        print(f"      ‚úÖ {len(chunks)} chunks criados")
        return chunks
    
    def process_all_documents(self):
        """Processa todos os documentos"""
        print("\nüîÑ Processando todos os documentos...")
        
        # Encontra documentos
        document_files = self.find_math_documents()
        
        if not document_files:
            print("‚ùå Nenhum documento encontrado!")
            return False
        
        # Processa cada documento
        all_chunks = []
        successful_files = 0
        
        print(f"\nüìö Processando {len(document_files)} documentos...")
        
        for i, file_path in enumerate(document_files):
            print(f"[{i+1}/{len(document_files)}] Processando {file_path.name}")
            try:
                chunks = self.process_single_document(file_path)
                if chunks:
                    all_chunks.extend(chunks)
                    successful_files += 1
            except Exception as e:
                print(f"‚ùå Erro ao processar {file_path.name}: {e}")
                continue
        
        self.documents = all_chunks
        
        print(f"\nüìä Resultado do processamento:")
        print(f"   üìÑ Arquivos processados: {successful_files}/{len(document_files)}")
        print(f"   üìù Total de chunks: {len(all_chunks)}")
        
        if not all_chunks:
            print("‚ùå Nenhum chunk foi criado!")
            return False
        
        return True
    
    def create_vectorstore(self):
        """Cria VectorStore com ChromaDB"""
        print("\nüíæ Criando VectorStore com ChromaDB...")
        
        if not self.documents:
            print("‚ùå Nenhum documento processado!")
            return False
        
        if not self.embeddings:
            print("‚ùå Embeddings n√£o configurados!")
            return False
        
        try:
            # Remove diret√≥rio existente se houver
            if os.path.exists(self.persist_dir):
                import shutil
                shutil.rmtree(self.persist_dir)
                print(f"üóëÔ∏è  Removido diret√≥rio existente: {self.persist_dir}")
            
            # Cria VectorStore
            print("üîÑ Criando embeddings e armazenando no ChromaDB...")
            
            self.vectorstore = Chroma.from_documents(
                documents=self.documents,
                embedding=self.embeddings,
                persist_directory=self.persist_dir
            )
            
            print(f"‚úÖ VectorStore criado em: {self.persist_dir}")
            print(f"üìä Documentos armazenados: {len(self.documents)}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao criar VectorStore: {e}")
            return False
    
    def test_vectorstore(self):
        """Testa o VectorStore criado"""
        print("\nüß™ Testando VectorStore...")
        
        if not self.vectorstore:
            print("‚ùå VectorStore n√£o foi criado!")
            return False
        
        # Testes de busca
        test_queries = [
            "fun√ß√£o quadr√°tica",
            "trigonometria",
            "geometria",
            "logaritmo",
            "progress√£o aritm√©tica"
        ]
        
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )
        
        for query in test_queries:
            print(f"\nüîç Testando busca: '{query}'")
            try:
                docs = retriever.get_relevant_documents(query)
                print(f"   üìä Encontrados: {len(docs)} documentos relevantes")
                
                for i, doc in enumerate(docs[:2]):  # Mostra apenas os 2 primeiros
                    source = doc.metadata.get('source', 'Desconhecido')
                    topic = doc.metadata.get('topic', 'Geral')
                    content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                    
                    print(f"      {i+1}. {topic} ({source})")
                    print(f"         {content_preview}")
                
            except Exception as e:
                print(f"   ‚ùå Erro na busca: {e}")
        
        return True

def main():
    """Fun√ß√£o principal"""
    print("üéì ENEM AI Helper - Criador de VectorStore com ChromaDB")
    print("=" * 60)
    
    # Verifica se a pasta matem√°tica existe
    math_folder = Path("./matem√°tica")
    if not math_folder.exists():
        print(f"‚ùå Pasta n√£o encontrada: {math_folder}")
        print("üí° Certifique-se de que a pasta 'matem√°tica' existe com documentos")
        return
    
    # Cria inst√¢ncia do criador
    creator = MathVectorStoreCreator()
    
    try:
        # 1. Configura embeddings
        creator.setup_embeddings()
        
        # 2. Processa documentos
        success = creator.process_all_documents()
        if not success:
            print("‚ùå Falha no processamento dos documentos")
            return
        
        # 3. Cria VectorStore
        success = creator.create_vectorstore()
        if not success:
            print("‚ùå Falha na cria√ß√£o da VectorStore")
            return
        
        # 4. Testa VectorStore
        creator.test_vectorstore()
        
        print("\nüéâ VectorStore criada com sucesso!")
        print("\nüöÄ Para usar no sistema principal:")
        print("1. Execute: streamlit run app.py")
        print("2. Configure sua API Key do OpenRouter")
        print("3. Selecione 'Matem√°tica'")
        print("4. O sistema carregar√° automaticamente a VectorStore criada!")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Processo interrompido pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro inesperado: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 